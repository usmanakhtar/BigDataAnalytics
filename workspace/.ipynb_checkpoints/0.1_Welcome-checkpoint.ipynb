{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome\n",
    "-------\n",
    "\n",
    "\n",
    "This is the first lab on PySpark \n",
    "\n",
    "\n",
    "#### Lab on Map Reduce  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 is to Import the Sesssion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Step 1: Start Spark Session\n",
    "spark = SparkSession.builder.appName(\"MapReduceWordCount\").getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Sample data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = [\"hello world\", \"hello map reduce\", \"map map reduce\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Step 3: Parallelize the data (this simulates loading data across nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.parallelize(text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4:   FlatMap - Split lines into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = rdd.flatMap(lambda line: line.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Map - Turn each word into a (word, 1) pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pairs = words.map(lambda word: (word, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: ReduceByKey - Count each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = word_pairs.reduceByKey(lambda a, b: a + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Result set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world: 1\n",
      "map: 3\n",
      "hello: 2\n",
      "reduce: 2\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Collect and print\n",
    "result = word_counts.collect()\n",
    "for word, count in result:\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Count total sales per product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('apple', 7), ('banana', 3)]\n"
     ]
    }
   ],
   "source": [
    "# Sample: (\"Product\", Quantity)\n",
    "data = [(\"apple\", 3), (\"banana\", 1), (\"apple\", 4), (\"banana\", 2)]\n",
    "\n",
    "rdd = spark.sparkContext.parallelize(data)\n",
    "result = rdd.reduceByKey(lambda x, y: x + y).collect()\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Output: [2, 4, 6]\n"
     ]
    }
   ],
   "source": [
    "# Get SparkContext from session\n",
    "sc = spark.sparkContext\n",
    "\n",
    "rdd = sc.parallelize([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "# Keep only even numbers\n",
    "filtered = rdd.filter(lambda x: x % 2 == 0)\n",
    "\n",
    "print(\"Filtered Output:\", filtered.collect())  # [2, 4, 6]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distinct - Remove the duplicats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct Output: [1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([1, 2, 2, 3, 4, 4, 5])\n",
    "\n",
    "distinct_rdd = rdd.distinct()\n",
    "\n",
    "print(\"Distinct Output:\", distinct_rdd.collect())  # [1, 2, 3, 4, 5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted Output: [('banana', 1), ('apple', 3), ('orange', 5)]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([(\"apple\", 3), (\"banana\", 1), (\"orange\", 5)])\n",
    "\n",
    "# Sort by quantity (ascending)\n",
    "sorted_rdd = rdd.sortBy(lambda x: x[1])\n",
    "\n",
    "print(\"Sorted Output:\", sorted_rdd.collect())\n",
    "# Output: [('banana', 1), ('apple', 3), ('orange', 5)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lab on PySpark \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "| name|\n",
      "+-----+\n",
      "|Alice|\n",
      "|  Bob|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Running the SPARK SQL Code \n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder.appName(\"SQLExample\").getOrCreate()\n",
    "\n",
    "# Sample data\n",
    "data = [(\"Alice\", 34), (\"Bob\", 45), (\"Charlie\", 29)]\n",
    "columns = [\"name\", \"age\"]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Register DataFrame as SQL temporary view\n",
    "df.createOrReplaceTempView(\"people\")\n",
    "\n",
    "# Run SQL query\n",
    "result = spark.sql(\"SELECT name FROM people WHERE age > 30\")\n",
    "result.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that there are some input data available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿The Project Gutenberg EBook of The Prince, by Nicolo Machiavelli\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use it under the terms of the Project Gutenberg License included\n",
      "with this eBook or online at www.gutenberg.org\n",
      "\n",
      "\n",
      "Title: The Prince\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# All the test data sets are located in the `data` directory.\n",
    "# You can preview them using unix command such as `cat`, `head`, `tail`,  `ls`,  etc. \n",
    "# in `shell` cells marked with the `%%sh` magic, e.g.: \n",
    "\n",
    "head -n 10 /home/jovyan/data/prince_by_machiavelli.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize a SparkSession\n",
    "spark = SparkSession.builder.appName(\"RDDExample\").getOrCreate()\n",
    "\n",
    "# Get the SparkContext from the SparkSession\n",
    "sc = spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if spark is available and what version are we using (should be 2.1+):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `spark` is the main entry point for all spark related operations.\n",
    "# It is an instance of SparkSession and pyspark automatically creates one for you.\n",
    "# Another one is `sc` an instance of SparkContext, which is used for low lever RRD API.\n",
    "\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to run a simple `Spark` program to compute the number of occurences of words in Machiavelli's \"Prince\", and display ten most frequent ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3108, 'the'), (2107, 'to'), (1935, 'and'), (1802, 'of'), (993, 'in'), (920, 'he'), (779, 'a'), (745, 'that'), (640, 'his'), (585, 'it')]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize a SparkSession\n",
    "spark = SparkSession.builder.appName(\"RDDExample\").getOrCreate()\n",
    "\n",
    "# Get the SparkContext from the SparkSession\n",
    "sc = spark.sparkContext\n",
    "\n",
    "import operator\n",
    "import re\n",
    "\n",
    "# Read the file and compute word counts\n",
    "wordCountRDD = sc.textFile('/home/jovyan/data/prince_by_machiavelli.txt') \\\n",
    "    .flatMap(lambda line: re.split(r'[^a-z\\-\\']+', line.lower())) \\\n",
    "    .filter(lambda word: len(word) > 0) \\\n",
    "    .map(lambda word: (word, 1)) \\\n",
    "    .reduceByKey(operator.add)\n",
    "\n",
    "# Sort by count descending and take top 10\n",
    "top10Words = wordCountRDD \\\n",
    "    .map(lambda kv: (kv[1], kv[0])) \\\n",
    "    .sortByKey(False) \\\n",
    "    .take(10)\n",
    "\n",
    "# Print results\n",
    "print(top10Words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark SQL is a higer level API for structured data. The data are represented in `data frames` - table like object with columns and rows concenptully similar to `panadas` or `R` data fames.\n",
    "\n",
    "Let's use Spark SQL to display a table with the 10 least frequent words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[word: string, count: bigint]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A data frame can be created from an RDD;\n",
    "# schema defines the names (and types) of columns.\n",
    "\n",
    "wordCountDF = spark.createDataFrame(wordCountRDD, schema = ['word', 'count'])\n",
    "\n",
    "# it just means: sort by column `count` and take the first ten elements\n",
    "\n",
    "bottom10Words = wordCountDF.sort('count').limit(10)\n",
    "\n",
    "# `display` function can be used to display data frames (and also all other sorts of objects)\n",
    "display(bottom10Words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the results to a csv file.\n",
    "\n",
    "For the tutorial all the output files are saved in the `output` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frames can be saved in many common 'table' formats, for example `csv`.\n",
    "# the `mode='overwrite'` tells Spark to overwite the output file is it exists\n",
    "\n",
    "wordCountDF.write.csv('output/prince-word-count.csv', mode='overwrite', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's preview the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 56\n",
      "-rw-r--r-- 1 jovyan users 28518 Apr  6 08:39 part-00000-398732c1-e36b-49a9-9e81-616617c9b8b3-c000.csv\n",
      "-rw-r--r-- 1 jovyan users 28506 Apr  6 08:39 part-00001-398732c1-e36b-49a9-9e81-616617c9b8b3-c000.csv\n",
      "-rw-r--r-- 1 jovyan users     0 Apr  6 08:39 _SUCCESS\n",
      "\n",
      "Content:\n",
      "word,count\n",
      "of,1802\n",
      "by,506\n",
      "this,366\n",
      "for,444\n",
      "use,30\n",
      "anyone,5\n",
      "at,210\n",
      "no,114\n",
      "cost,4\n"
     ]
    }
   ],
   "source": [
    "%%sh \n",
    "\n",
    "# Same as with the input data sets, we can use the `%%sh` cells to preview the \n",
    "# files produced to the `output` directory.\n",
    "\n",
    "# Please note that output we have produced above is actually a directory:\n",
    "\n",
    "ls  -l output/prince-word-count.csv\n",
    "\n",
    "# The `part-*` files inside contain the actual data.\n",
    "\n",
    "echo\n",
    "echo \"Content:\"\n",
    "\n",
    "head -n 10 output/prince-word-count.csv/part-00000-*.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can use python `matplotlib` to visualise the result.\n",
    "\n",
    "Let's plot the histogram of the distribution of word counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# we can convert (small) Spark data frames to `pandas`\n",
    "wordCountPDF = wordCountDF.toPandas()\n",
    "\n",
    "# and then use pyplot (plt) to display the results\n",
    "# Please note that we call `plt.close()` first - this is needed for Databricks \n",
    "# to start a new plot.\n",
    "\n",
    "plt.close()\n",
    "plt.hist(wordCountPDF['count'], bins = 20, log = True)\n",
    "plt.show()\n",
    "display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now play around modifyging some pieces of the code.\n",
    "\n",
    "When you are done and you are running off the local machine remeber **to close the notebook with `File/Close and Halt`**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
